{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning a transformer for a Sentiment Analysis Web App\n",
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import transformers\n",
    "from transformers import DistilBertModel, DistilBertTokenizerFast, DistilBertForSequenceClassification, AdamW\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device=torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDb dataset is retrieved from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imdb_split(split_dir):\n",
    "    split_dir = Path(split_dir)\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for label_dir in [\"pos\", \"neg\"]:\n",
    "        for text_file in (split_dir/label_dir).iterdir():\n",
    "            texts.append(text_file.read_text(encoding=\"utf8\"))\n",
    "            labels.append(0 if label_dir is \"neg\" else 1)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = read_imdb_split('aclImdb/train')\n",
    "test_texts, test_labels = read_imdb_split('aclImdb/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews (combined): train = 25000, test = 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_texts), len(test_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I find it so amazing that even after all these years, we are STILL talking about this movie! Obviously this movie wasn't THAT bad or else people wouldn't even BOTHER to talk about it. I personally enjoyed this film immensly, and still do! I guess this film isn't for everyone, but it certainly did touch the hearts of many. <br /><br />As for those that think that this film is \"overrated\" or \"over-hyped\"...well, we only have the movie-going public to thank for that! lol* You see, it's not CRITICS/article writers that make a film \"HUGE\" or a \"HIT\" with the general movie-going public. PEOPLE make the film a huge success. With Titanic, everyone was in awe. Let's face it, a film like this had never been made before. At least not with the type of special effects needed to really capture the essence of the ship actually sinking. This film is so accurate that even James Cameron timed the actual sinking of the ship in the film with the REAL sinking that fateful day in April 1912. Even the silverware for goodness sakes matched! <br /><br />Give this movie a break you guys! The critics thought this movie would sink BIG time! When this movie actually came out and people started hearing by WORD OF MOUTH (which is the BEST form of advertisement mind you) that this was a good/decent/movie worth seeing, then everyone started flocking to the theaters in droves to see this movie...not once, not twice, but maybe 3 times and more! So, I really wouldn't say that this movie was \"overhyped\"...at least not like the buildup for the MATRIX reloaded or the HULK is being \"overhyped\". ha! Critics didn't even think that Titanic would make enough money to cover Cameron's gigantic film budget that it took to make this mammoth of a film. However, the films money took care of that 200 million budget and MUCH more! <br /><br />Personally, I LOVE this film. However, this film might not be for everyone. DOn't say that this film sucks just because of romance though! THat is the most sexist thing I've ever heard! Disliking a movie just because it has romance in it! The story was sweet. The dialogue could have been better, but let's face it...the REAL star of the movie wasn't Leo or Kate...it was that GIGANTIC Ship! I think all of the actors including DiCaprio and Winslet did a fine job. It's not thier best work (I've seen much BETTER work from both of them) but it wasn't the WORST I've seen on screen before. Give them a break!<br /><br />\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[50])\n",
    "print(train_labels[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "val_dataset = IMDbDataset(val_encodings, val_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification with DistilBERT and Hugging Face\n",
    "\n",
    "We select DistilBert for its limited size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77125ae1b89244fb9c59ec5009210500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6433f8a38428494097114ae35c00a7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1250.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6849543571472168, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.008, 'step': 10}\n",
      "{'loss': 0.6793449401855469, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.016, 'step': 20}\n",
      "{'loss': 0.6858637809753418, 'learning_rate': 3e-06, 'epoch': 0.024, 'step': 30}\n",
      "{'loss': 0.6798263549804687, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.032, 'step': 40}\n",
      "{'loss': 0.6834714889526368, 'learning_rate': 5e-06, 'epoch': 0.04, 'step': 50}\n",
      "{'loss': 0.6793785095214844, 'learning_rate': 6e-06, 'epoch': 0.048, 'step': 60}\n",
      "{'loss': 0.6545303344726563, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.056, 'step': 70}\n",
      "{'loss': 0.6330799102783203, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.064, 'step': 80}\n",
      "{'loss': 0.5784263610839844, 'learning_rate': 9e-06, 'epoch': 0.072, 'step': 90}\n",
      "{'loss': 0.4934104919433594, 'learning_rate': 1e-05, 'epoch': 0.08, 'step': 100}\n",
      "{'loss': 0.422637939453125, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.088, 'step': 110}\n",
      "{'loss': 0.35782852172851565, 'learning_rate': 1.2e-05, 'epoch': 0.096, 'step': 120}\n",
      "{'loss': 0.3924774169921875, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.104, 'step': 130}\n",
      "{'loss': 0.3967620849609375, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.112, 'step': 140}\n",
      "{'loss': 0.37173004150390626, 'learning_rate': 1.5e-05, 'epoch': 0.12, 'step': 150}\n",
      "{'loss': 0.309552001953125, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.128, 'step': 160}\n",
      "{'loss': 0.2780418395996094, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.136, 'step': 170}\n",
      "{'loss': 0.27599563598632815, 'learning_rate': 1.8e-05, 'epoch': 0.144, 'step': 180}\n",
      "{'loss': 0.2076568603515625, 'learning_rate': 1.9e-05, 'epoch': 0.152, 'step': 190}\n",
      "{'loss': 0.356024169921875, 'learning_rate': 2e-05, 'epoch': 0.16, 'step': 200}\n",
      "{'loss': 0.3171363830566406, 'learning_rate': 2.1e-05, 'epoch': 0.168, 'step': 210}\n",
      "{'loss': 0.4197845458984375, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.176, 'step': 220}\n",
      "{'loss': 0.29525222778320315, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.184, 'step': 230}\n",
      "{'loss': 0.2791107177734375, 'learning_rate': 2.4e-05, 'epoch': 0.192, 'step': 240}\n",
      "{'loss': 0.34086761474609373, 'learning_rate': 2.5e-05, 'epoch': 0.2, 'step': 250}\n",
      "{'loss': 0.4017005920410156, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.208, 'step': 260}\n",
      "{'loss': 0.3282508850097656, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.216, 'step': 270}\n",
      "{'loss': 0.2643760681152344, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.224, 'step': 280}\n",
      "{'loss': 0.3290138244628906, 'learning_rate': 2.9e-05, 'epoch': 0.232, 'step': 290}\n",
      "{'loss': 0.2558258056640625, 'learning_rate': 3e-05, 'epoch': 0.24, 'step': 300}\n",
      "{'loss': 0.35167083740234373, 'learning_rate': 3.1e-05, 'epoch': 0.248, 'step': 310}\n",
      "{'loss': 0.35281219482421877, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.256, 'step': 320}\n",
      "{'loss': 0.30349578857421877, 'learning_rate': 3.3e-05, 'epoch': 0.264, 'step': 330}\n",
      "{'loss': 0.19995880126953125, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.272, 'step': 340}\n",
      "{'loss': 0.42815093994140624, 'learning_rate': 3.5e-05, 'epoch': 0.28, 'step': 350}\n",
      "{'loss': 0.3247314453125, 'learning_rate': 3.6e-05, 'epoch': 0.288, 'step': 360}\n",
      "{'loss': 0.25850372314453124, 'learning_rate': 3.7e-05, 'epoch': 0.296, 'step': 370}\n",
      "{'loss': 0.24181976318359374, 'learning_rate': 3.8e-05, 'epoch': 0.304, 'step': 380}\n",
      "{'loss': 0.28385162353515625, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.312, 'step': 390}\n",
      "{'loss': 0.22495574951171876, 'learning_rate': 4e-05, 'epoch': 0.32, 'step': 400}\n",
      "{'loss': 0.31485137939453123, 'learning_rate': 4.1e-05, 'epoch': 0.328, 'step': 410}\n",
      "{'loss': 0.33631134033203125, 'learning_rate': 4.2e-05, 'epoch': 0.336, 'step': 420}\n",
      "{'loss': 0.43694915771484377, 'learning_rate': 4.3e-05, 'epoch': 0.344, 'step': 430}\n",
      "{'loss': 0.29889984130859376, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.352, 'step': 440}\n",
      "{'loss': 0.42800140380859375, 'learning_rate': 4.5e-05, 'epoch': 0.36, 'step': 450}\n",
      "{'loss': 0.34485931396484376, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.368, 'step': 460}\n",
      "{'loss': 0.40650482177734376, 'learning_rate': 4.7e-05, 'epoch': 0.376, 'step': 470}\n",
      "{'loss': 0.29892120361328123, 'learning_rate': 4.8e-05, 'epoch': 0.384, 'step': 480}\n",
      "{'loss': 0.34713287353515626, 'learning_rate': 4.9e-05, 'epoch': 0.392, 'step': 490}\n",
      "{'loss': 0.32144012451171877, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\miniconda3\\envs\\sentiment\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.23261871337890624, 'learning_rate': 4.984615384615385e-05, 'epoch': 0.408, 'step': 510}\n",
      "{'loss': 0.31630096435546873, 'learning_rate': 4.969230769230769e-05, 'epoch': 0.416, 'step': 520}\n",
      "{'loss': 0.289892578125, 'learning_rate': 4.953846153846154e-05, 'epoch': 0.424, 'step': 530}\n",
      "{'loss': 0.25572662353515624, 'learning_rate': 4.9384615384615384e-05, 'epoch': 0.432, 'step': 540}\n",
      "{'loss': 0.2310638427734375, 'learning_rate': 4.923076923076924e-05, 'epoch': 0.44, 'step': 550}\n",
      "{'loss': 0.31404266357421873, 'learning_rate': 4.907692307692308e-05, 'epoch': 0.448, 'step': 560}\n",
      "{'loss': 0.25184478759765627, 'learning_rate': 4.892307692307693e-05, 'epoch': 0.456, 'step': 570}\n",
      "{'loss': 0.23512115478515624, 'learning_rate': 4.876923076923077e-05, 'epoch': 0.464, 'step': 580}\n",
      "{'loss': 0.3182830810546875, 'learning_rate': 4.861538461538462e-05, 'epoch': 0.472, 'step': 590}\n",
      "{'loss': 0.24281463623046876, 'learning_rate': 4.846153846153846e-05, 'epoch': 0.48, 'step': 600}\n",
      "{'loss': 0.23890838623046876, 'learning_rate': 4.830769230769231e-05, 'epoch': 0.488, 'step': 610}\n",
      "{'loss': 0.358367919921875, 'learning_rate': 4.815384615384615e-05, 'epoch': 0.496, 'step': 620}\n",
      "{'loss': 0.36671905517578124, 'learning_rate': 4.8e-05, 'epoch': 0.504, 'step': 630}\n",
      "{'loss': 0.26955718994140626, 'learning_rate': 4.784615384615384e-05, 'epoch': 0.512, 'step': 640}\n",
      "{'loss': 0.3460784912109375, 'learning_rate': 4.76923076923077e-05, 'epoch': 0.52, 'step': 650}\n",
      "{'loss': 0.2358734130859375, 'learning_rate': 4.753846153846154e-05, 'epoch': 0.528, 'step': 660}\n",
      "{'loss': 0.30140380859375, 'learning_rate': 4.738461538461539e-05, 'epoch': 0.536, 'step': 670}\n",
      "{'loss': 0.20692901611328124, 'learning_rate': 4.723076923076923e-05, 'epoch': 0.544, 'step': 680}\n",
      "{'loss': 0.2798797607421875, 'learning_rate': 4.707692307692308e-05, 'epoch': 0.552, 'step': 690}\n",
      "{'loss': 0.246728515625, 'learning_rate': 4.692307692307693e-05, 'epoch': 0.56, 'step': 700}\n",
      "{'loss': 0.25247344970703123, 'learning_rate': 4.676923076923077e-05, 'epoch': 0.568, 'step': 710}\n",
      "{'loss': 0.25061187744140623, 'learning_rate': 4.661538461538462e-05, 'epoch': 0.576, 'step': 720}\n",
      "{'loss': 0.29680328369140624, 'learning_rate': 4.646153846153846e-05, 'epoch': 0.584, 'step': 730}\n",
      "{'loss': 0.2278839111328125, 'learning_rate': 4.630769230769231e-05, 'epoch': 0.592, 'step': 740}\n",
      "{'loss': 0.2083221435546875, 'learning_rate': 4.615384615384616e-05, 'epoch': 0.6, 'step': 750}\n",
      "{'loss': 0.261041259765625, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.608, 'step': 760}\n",
      "{'loss': 0.376123046875, 'learning_rate': 4.584615384615385e-05, 'epoch': 0.616, 'step': 770}\n",
      "{'loss': 0.283868408203125, 'learning_rate': 4.56923076923077e-05, 'epoch': 0.624, 'step': 780}\n",
      "{'loss': 0.268731689453125, 'learning_rate': 4.553846153846154e-05, 'epoch': 0.632, 'step': 790}\n",
      "{'loss': 0.296624755859375, 'learning_rate': 4.538461538461539e-05, 'epoch': 0.64, 'step': 800}\n",
      "{'loss': 0.3052215576171875, 'learning_rate': 4.523076923076923e-05, 'epoch': 0.648, 'step': 810}\n",
      "{'loss': 0.4093597412109375, 'learning_rate': 4.507692307692308e-05, 'epoch': 0.656, 'step': 820}\n",
      "{'loss': 0.283599853515625, 'learning_rate': 4.492307692307692e-05, 'epoch': 0.664, 'step': 830}\n",
      "{'loss': 0.3228973388671875, 'learning_rate': 4.476923076923077e-05, 'epoch': 0.672, 'step': 840}\n",
      "{'loss': 0.2194854736328125, 'learning_rate': 4.461538461538462e-05, 'epoch': 0.68, 'step': 850}\n",
      "{'loss': 0.3349029541015625, 'learning_rate': 4.4461538461538466e-05, 'epoch': 0.688, 'step': 860}\n",
      "{'loss': 0.270892333984375, 'learning_rate': 4.430769230769231e-05, 'epoch': 0.696, 'step': 870}\n",
      "{'loss': 0.3116302490234375, 'learning_rate': 4.415384615384616e-05, 'epoch': 0.704, 'step': 880}\n",
      "{'loss': 0.3030181884765625, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.712, 'step': 890}\n",
      "{'loss': 0.3057403564453125, 'learning_rate': 4.384615384615385e-05, 'epoch': 0.72, 'step': 900}\n",
      "{'loss': 0.31396484375, 'learning_rate': 4.3692307692307696e-05, 'epoch': 0.728, 'step': 910}\n",
      "{'loss': 0.26199951171875, 'learning_rate': 4.353846153846154e-05, 'epoch': 0.736, 'step': 920}\n",
      "{'loss': 0.2525146484375, 'learning_rate': 4.338461538461539e-05, 'epoch': 0.744, 'step': 930}\n",
      "{'loss': 0.2480743408203125, 'learning_rate': 4.323076923076923e-05, 'epoch': 0.752, 'step': 940}\n",
      "{'loss': 0.234832763671875, 'learning_rate': 4.3076923076923084e-05, 'epoch': 0.76, 'step': 950}\n",
      "{'loss': 0.276507568359375, 'learning_rate': 4.2923076923076926e-05, 'epoch': 0.768, 'step': 960}\n",
      "{'loss': 0.351507568359375, 'learning_rate': 4.2769230769230775e-05, 'epoch': 0.776, 'step': 970}\n",
      "{'loss': 0.2229736328125, 'learning_rate': 4.2615384615384617e-05, 'epoch': 0.784, 'step': 980}\n",
      "{'loss': 0.1665618896484375, 'learning_rate': 4.2461538461538465e-05, 'epoch': 0.792, 'step': 990}\n",
      "{'loss': 0.4358123779296875, 'learning_rate': 4.230769230769231e-05, 'epoch': 0.8, 'step': 1000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea79381ad9a4c8cbe77fd49200fed15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=79.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.24497871668338775, 'epoch': 0.8, 'step': 1000}\n",
      "{'loss': 0.2187286376953125, 'learning_rate': 4.2153846153846156e-05, 'epoch': 0.808, 'step': 1010}\n",
      "{'loss': 0.2787933349609375, 'learning_rate': 4.2e-05, 'epoch': 0.816, 'step': 1020}\n",
      "{'loss': 0.26097412109375, 'learning_rate': 4.1846153846153846e-05, 'epoch': 0.824, 'step': 1030}\n",
      "{'loss': 0.2312164306640625, 'learning_rate': 4.169230769230769e-05, 'epoch': 0.832, 'step': 1040}\n",
      "{'loss': 0.3315216064453125, 'learning_rate': 4.1538461538461544e-05, 'epoch': 0.84, 'step': 1050}\n",
      "{'loss': 0.2529022216796875, 'learning_rate': 4.1384615384615386e-05, 'epoch': 0.848, 'step': 1060}\n",
      "{'loss': 0.2635345458984375, 'learning_rate': 4.1230769230769234e-05, 'epoch': 0.856, 'step': 1070}\n",
      "{'loss': 0.1777740478515625, 'learning_rate': 4.1076923076923076e-05, 'epoch': 0.864, 'step': 1080}\n",
      "{'loss': 0.353619384765625, 'learning_rate': 4.0923076923076925e-05, 'epoch': 0.872, 'step': 1090}\n",
      "{'loss': 0.26666259765625, 'learning_rate': 4.0769230769230773e-05, 'epoch': 0.88, 'step': 1100}\n",
      "{'loss': 0.1757049560546875, 'learning_rate': 4.0615384615384615e-05, 'epoch': 0.888, 'step': 1110}\n",
      "{'loss': 0.1666839599609375, 'learning_rate': 4.0461538461538464e-05, 'epoch': 0.896, 'step': 1120}\n",
      "{'loss': 0.266070556640625, 'learning_rate': 4.0307692307692306e-05, 'epoch': 0.904, 'step': 1130}\n",
      "{'loss': 0.21444091796875, 'learning_rate': 4.0153846153846155e-05, 'epoch': 0.912, 'step': 1140}\n",
      "{'loss': 0.2749847412109375, 'learning_rate': 4e-05, 'epoch': 0.92, 'step': 1150}\n",
      "{'loss': 0.2320526123046875, 'learning_rate': 3.984615384615385e-05, 'epoch': 0.928, 'step': 1160}\n",
      "{'loss': 0.216229248046875, 'learning_rate': 3.9692307692307694e-05, 'epoch': 0.936, 'step': 1170}\n",
      "{'loss': 0.1888916015625, 'learning_rate': 3.953846153846154e-05, 'epoch': 0.944, 'step': 1180}\n",
      "{'loss': 0.319317626953125, 'learning_rate': 3.9384615384615384e-05, 'epoch': 0.952, 'step': 1190}\n",
      "{'loss': 0.240435791015625, 'learning_rate': 3.923076923076923e-05, 'epoch': 0.96, 'step': 1200}\n",
      "{'loss': 0.2944580078125, 'learning_rate': 3.9076923076923075e-05, 'epoch': 0.968, 'step': 1210}\n",
      "{'loss': 0.1953826904296875, 'learning_rate': 3.8923076923076924e-05, 'epoch': 0.976, 'step': 1220}\n",
      "{'loss': 0.3049163818359375, 'learning_rate': 3.8769230769230766e-05, 'epoch': 0.984, 'step': 1230}\n",
      "{'loss': 0.3019775390625, 'learning_rate': 3.861538461538462e-05, 'epoch': 0.992, 'step': 1240}\n",
      "{'loss': 0.223492431640625, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.0, 'step': 1250}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e45fb0c19d4a9e93761c2c281f6ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1250.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1304107666015625, 'learning_rate': 3.830769230769231e-05, 'epoch': 1.008, 'step': 1260}\n",
      "{'loss': 0.1747039794921875, 'learning_rate': 3.8153846153846153e-05, 'epoch': 1.016, 'step': 1270}\n",
      "{'loss': 0.15675048828125, 'learning_rate': 3.8e-05, 'epoch': 1.024, 'step': 1280}\n",
      "{'loss': 0.186334228515625, 'learning_rate': 3.784615384615385e-05, 'epoch': 1.032, 'step': 1290}\n",
      "{'loss': 0.1932647705078125, 'learning_rate': 3.769230769230769e-05, 'epoch': 1.04, 'step': 1300}\n",
      "{'loss': 0.15980224609375, 'learning_rate': 3.753846153846154e-05, 'epoch': 1.048, 'step': 1310}\n",
      "{'loss': 0.1334136962890625, 'learning_rate': 3.738461538461538e-05, 'epoch': 1.056, 'step': 1320}\n",
      "{'loss': 0.174884033203125, 'learning_rate': 3.723076923076923e-05, 'epoch': 1.064, 'step': 1330}\n",
      "{'loss': 0.1698638916015625, 'learning_rate': 3.707692307692308e-05, 'epoch': 1.072, 'step': 1340}\n",
      "{'loss': 0.1145416259765625, 'learning_rate': 3.692307692307693e-05, 'epoch': 1.08, 'step': 1350}\n",
      "{'loss': 0.1808868408203125, 'learning_rate': 3.676923076923077e-05, 'epoch': 1.088, 'step': 1360}\n",
      "{'loss': 0.160443115234375, 'learning_rate': 3.661538461538462e-05, 'epoch': 1.096, 'step': 1370}\n",
      "{'loss': 0.08626708984375, 'learning_rate': 3.646153846153846e-05, 'epoch': 1.104, 'step': 1380}\n",
      "{'loss': 0.1434661865234375, 'learning_rate': 3.630769230769231e-05, 'epoch': 1.112, 'step': 1390}\n",
      "{'loss': 0.1483612060546875, 'learning_rate': 3.615384615384615e-05, 'epoch': 1.12, 'step': 1400}\n",
      "{'loss': 0.1810333251953125, 'learning_rate': 3.6e-05, 'epoch': 1.1280000000000001, 'step': 1410}\n",
      "{'loss': 0.116729736328125, 'learning_rate': 3.584615384615384e-05, 'epoch': 1.1360000000000001, 'step': 1420}\n",
      "{'loss': 0.092156982421875, 'learning_rate': 3.569230769230769e-05, 'epoch': 1.144, 'step': 1430}\n",
      "{'loss': 0.22562255859375, 'learning_rate': 3.553846153846154e-05, 'epoch': 1.152, 'step': 1440}\n",
      "{'loss': 0.1412628173828125, 'learning_rate': 3.538461538461539e-05, 'epoch': 1.16, 'step': 1450}\n",
      "{'loss': 0.1584442138671875, 'learning_rate': 3.523076923076923e-05, 'epoch': 1.168, 'step': 1460}\n",
      "{'loss': 0.1527496337890625, 'learning_rate': 3.507692307692308e-05, 'epoch': 1.176, 'step': 1470}\n",
      "{'loss': 0.1009674072265625, 'learning_rate': 3.492307692307693e-05, 'epoch': 1.184, 'step': 1480}\n",
      "{'loss': 0.2414886474609375, 'learning_rate': 3.476923076923077e-05, 'epoch': 1.192, 'step': 1490}\n",
      "{'loss': 0.27894287109375, 'learning_rate': 3.461538461538462e-05, 'epoch': 1.2, 'step': 1500}\n",
      "{'loss': 0.21531982421875, 'learning_rate': 3.446153846153846e-05, 'epoch': 1.208, 'step': 1510}\n",
      "{'loss': 0.18486328125, 'learning_rate': 3.430769230769231e-05, 'epoch': 1.216, 'step': 1520}\n",
      "{'loss': 0.1862457275390625, 'learning_rate': 3.415384615384615e-05, 'epoch': 1.224, 'step': 1530}\n",
      "{'loss': 0.2464569091796875, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.232, 'step': 1540}\n",
      "{'loss': 0.1327423095703125, 'learning_rate': 3.384615384615385e-05, 'epoch': 1.24, 'step': 1550}\n",
      "{'loss': 0.1857452392578125, 'learning_rate': 3.36923076923077e-05, 'epoch': 1.248, 'step': 1560}\n",
      "{'loss': 0.112164306640625, 'learning_rate': 3.353846153846154e-05, 'epoch': 1.256, 'step': 1570}\n",
      "{'loss': 0.1756805419921875, 'learning_rate': 3.338461538461539e-05, 'epoch': 1.264, 'step': 1580}\n",
      "{'loss': 0.2068511962890625, 'learning_rate': 3.323076923076923e-05, 'epoch': 1.272, 'step': 1590}\n",
      "{'loss': 0.226348876953125, 'learning_rate': 3.307692307692308e-05, 'epoch': 1.28, 'step': 1600}\n",
      "{'loss': 0.2051666259765625, 'learning_rate': 3.292307692307692e-05, 'epoch': 1.288, 'step': 1610}\n",
      "{'loss': 0.1741455078125, 'learning_rate': 3.276923076923077e-05, 'epoch': 1.296, 'step': 1620}\n",
      "{'loss': 0.1562042236328125, 'learning_rate': 3.261538461538462e-05, 'epoch': 1.304, 'step': 1630}\n",
      "{'loss': 0.1266815185546875, 'learning_rate': 3.2461538461538466e-05, 'epoch': 1.312, 'step': 1640}\n",
      "{'loss': 0.1849761962890625, 'learning_rate': 3.230769230769231e-05, 'epoch': 1.32, 'step': 1650}\n",
      "{'loss': 0.0873260498046875, 'learning_rate': 3.215384615384616e-05, 'epoch': 1.328, 'step': 1660}\n",
      "{'loss': 0.172088623046875, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.336, 'step': 1670}\n",
      "{'loss': 0.0960296630859375, 'learning_rate': 3.184615384615385e-05, 'epoch': 1.3439999999999999, 'step': 1680}\n",
      "{'loss': 0.2428436279296875, 'learning_rate': 3.1692307692307696e-05, 'epoch': 1.3519999999999999, 'step': 1690}\n",
      "{'loss': 0.2840606689453125, 'learning_rate': 3.153846153846154e-05, 'epoch': 1.3599999999999999, 'step': 1700}\n",
      "{'loss': 0.1476104736328125, 'learning_rate': 3.1384615384615386e-05, 'epoch': 1.3679999999999999, 'step': 1710}\n",
      "{'loss': 0.22822265625, 'learning_rate': 3.123076923076923e-05, 'epoch': 1.376, 'step': 1720}\n",
      "{'loss': 0.110333251953125, 'learning_rate': 3.107692307692308e-05, 'epoch': 1.384, 'step': 1730}\n",
      "{'loss': 0.132635498046875, 'learning_rate': 3.0923076923076926e-05, 'epoch': 1.392, 'step': 1740}\n",
      "{'loss': 0.2519439697265625, 'learning_rate': 3.0769230769230774e-05, 'epoch': 1.4, 'step': 1750}\n",
      "{'loss': 0.196697998046875, 'learning_rate': 3.0615384615384616e-05, 'epoch': 1.408, 'step': 1760}\n",
      "{'loss': 0.1394439697265625, 'learning_rate': 3.0461538461538465e-05, 'epoch': 1.416, 'step': 1770}\n",
      "{'loss': 0.2111846923828125, 'learning_rate': 3.030769230769231e-05, 'epoch': 1.424, 'step': 1780}\n",
      "{'loss': 0.1784454345703125, 'learning_rate': 3.0153846153846155e-05, 'epoch': 1.432, 'step': 1790}\n",
      "{'loss': 0.147943115234375, 'learning_rate': 3e-05, 'epoch': 1.44, 'step': 1800}\n",
      "{'loss': 0.1641845703125, 'learning_rate': 2.9846153846153846e-05, 'epoch': 1.448, 'step': 1810}\n",
      "{'loss': 0.23336181640625, 'learning_rate': 2.969230769230769e-05, 'epoch': 1.456, 'step': 1820}\n",
      "{'loss': 0.2387969970703125, 'learning_rate': 2.9538461538461543e-05, 'epoch': 1.464, 'step': 1830}\n",
      "{'loss': 0.16265869140625, 'learning_rate': 2.938461538461539e-05, 'epoch': 1.472, 'step': 1840}\n",
      "{'loss': 0.2149932861328125, 'learning_rate': 2.9230769230769234e-05, 'epoch': 1.48, 'step': 1850}\n",
      "{'loss': 0.1111328125, 'learning_rate': 2.907692307692308e-05, 'epoch': 1.488, 'step': 1860}\n",
      "{'loss': 0.245703125, 'learning_rate': 2.8923076923076925e-05, 'epoch': 1.496, 'step': 1870}\n",
      "{'loss': 0.130889892578125, 'learning_rate': 2.876923076923077e-05, 'epoch': 1.504, 'step': 1880}\n",
      "{'loss': 0.1322509765625, 'learning_rate': 2.8615384615384615e-05, 'epoch': 1.512, 'step': 1890}\n",
      "{'loss': 0.129217529296875, 'learning_rate': 2.846153846153846e-05, 'epoch': 1.52, 'step': 1900}\n",
      "{'loss': 0.1512115478515625, 'learning_rate': 2.8307692307692306e-05, 'epoch': 1.528, 'step': 1910}\n",
      "{'loss': 0.3054718017578125, 'learning_rate': 2.8153846153846154e-05, 'epoch': 1.536, 'step': 1920}\n",
      "{'loss': 0.1341552734375, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.544, 'step': 1930}\n",
      "{'loss': 0.114453125, 'learning_rate': 2.7846153846153848e-05, 'epoch': 1.552, 'step': 1940}\n",
      "{'loss': 0.14715576171875, 'learning_rate': 2.7692307692307694e-05, 'epoch': 1.56, 'step': 1950}\n",
      "{'loss': 0.047174072265625, 'learning_rate': 2.7538461538461542e-05, 'epoch': 1.568, 'step': 1960}\n",
      "{'loss': 0.10972900390625, 'learning_rate': 2.7384615384615387e-05, 'epoch': 1.576, 'step': 1970}\n",
      "{'loss': 0.100970458984375, 'learning_rate': 2.7230769230769233e-05, 'epoch': 1.584, 'step': 1980}\n",
      "{'loss': 0.2146240234375, 'learning_rate': 2.7076923076923078e-05, 'epoch': 1.592, 'step': 1990}\n",
      "{'loss': 0.12093505859375, 'learning_rate': 2.6923076923076923e-05, 'epoch': 1.6, 'step': 2000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a64cc4d909469da5048cbbb2f518ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=79.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.267195578956604, 'epoch': 1.6, 'step': 2000}\n",
      "{'loss': 0.1015625, 'learning_rate': 2.676923076923077e-05, 'epoch': 1.608, 'step': 2010}\n",
      "{'loss': 0.188616943359375, 'learning_rate': 2.6615384615384614e-05, 'epoch': 1.616, 'step': 2020}\n",
      "{'loss': 0.17333984375, 'learning_rate': 2.6461538461538466e-05, 'epoch': 1.624, 'step': 2030}\n",
      "{'loss': 0.09266357421875, 'learning_rate': 2.630769230769231e-05, 'epoch': 1.6320000000000001, 'step': 2040}\n",
      "{'loss': 0.2500244140625, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.6400000000000001, 'step': 2050}\n",
      "{'loss': 0.141168212890625, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.6480000000000001, 'step': 2060}\n",
      "{'loss': 0.244183349609375, 'learning_rate': 2.5846153846153847e-05, 'epoch': 1.6560000000000001, 'step': 2070}\n",
      "{'loss': 0.071533203125, 'learning_rate': 2.5692307692307692e-05, 'epoch': 1.6640000000000001, 'step': 2080}\n",
      "{'loss': 0.180364990234375, 'learning_rate': 2.5538461538461538e-05, 'epoch': 1.6720000000000002, 'step': 2090}\n",
      "{'loss': 0.170086669921875, 'learning_rate': 2.5384615384615383e-05, 'epoch': 1.6800000000000002, 'step': 2100}\n",
      "{'loss': 0.11153564453125, 'learning_rate': 2.523076923076923e-05, 'epoch': 1.688, 'step': 2110}\n",
      "{'loss': 0.289129638671875, 'learning_rate': 2.5076923076923077e-05, 'epoch': 1.696, 'step': 2120}\n",
      "{'loss': 0.207684326171875, 'learning_rate': 2.4923076923076926e-05, 'epoch': 1.704, 'step': 2130}\n",
      "{'loss': 0.16514892578125, 'learning_rate': 2.476923076923077e-05, 'epoch': 1.712, 'step': 2140}\n",
      "{'loss': 0.288751220703125, 'learning_rate': 2.461538461538462e-05, 'epoch': 1.72, 'step': 2150}\n",
      "{'loss': 0.177569580078125, 'learning_rate': 2.4461538461538465e-05, 'epoch': 1.728, 'step': 2160}\n",
      "{'loss': 0.140850830078125, 'learning_rate': 2.430769230769231e-05, 'epoch': 1.736, 'step': 2170}\n",
      "{'loss': 0.13409423828125, 'learning_rate': 2.4153846153846155e-05, 'epoch': 1.744, 'step': 2180}\n",
      "{'loss': 0.11883544921875, 'learning_rate': 2.4e-05, 'epoch': 1.752, 'step': 2190}\n",
      "{'loss': 0.2150146484375, 'learning_rate': 2.384615384615385e-05, 'epoch': 1.76, 'step': 2200}\n",
      "{'loss': 0.197894287109375, 'learning_rate': 2.3692307692307695e-05, 'epoch': 1.768, 'step': 2210}\n",
      "{'loss': 0.076251220703125, 'learning_rate': 2.353846153846154e-05, 'epoch': 1.776, 'step': 2220}\n",
      "{'loss': 0.121319580078125, 'learning_rate': 2.3384615384615385e-05, 'epoch': 1.784, 'step': 2230}\n",
      "{'loss': 0.186102294921875, 'learning_rate': 2.323076923076923e-05, 'epoch': 1.792, 'step': 2240}\n",
      "{'loss': 0.09434814453125, 'learning_rate': 2.307692307692308e-05, 'epoch': 1.8, 'step': 2250}\n",
      "{'loss': 0.1506591796875, 'learning_rate': 2.2923076923076924e-05, 'epoch': 1.808, 'step': 2260}\n",
      "{'loss': 0.188153076171875, 'learning_rate': 2.276923076923077e-05, 'epoch': 1.8159999999999998, 'step': 2270}\n",
      "{'loss': 0.295068359375, 'learning_rate': 2.2615384615384615e-05, 'epoch': 1.8239999999999998, 'step': 2280}\n",
      "{'loss': 0.141986083984375, 'learning_rate': 2.246153846153846e-05, 'epoch': 1.8319999999999999, 'step': 2290}\n",
      "{'loss': 0.0999267578125, 'learning_rate': 2.230769230769231e-05, 'epoch': 1.8399999999999999, 'step': 2300}\n",
      "{'loss': 0.113385009765625, 'learning_rate': 2.2153846153846154e-05, 'epoch': 1.8479999999999999, 'step': 2310}\n",
      "{'loss': 0.131744384765625, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.8559999999999999, 'step': 2320}\n",
      "{'loss': 0.344232177734375, 'learning_rate': 2.1846153846153848e-05, 'epoch': 1.8639999999999999, 'step': 2330}\n",
      "{'loss': 0.11802978515625, 'learning_rate': 2.1692307692307693e-05, 'epoch': 1.8719999999999999, 'step': 2340}\n",
      "{'loss': 0.155633544921875, 'learning_rate': 2.1538461538461542e-05, 'epoch': 1.88, 'step': 2350}\n",
      "{'loss': 0.1129150390625, 'learning_rate': 2.1384615384615387e-05, 'epoch': 1.888, 'step': 2360}\n",
      "{'loss': 0.1398681640625, 'learning_rate': 2.1230769230769233e-05, 'epoch': 1.896, 'step': 2370}\n",
      "{'loss': 0.192437744140625, 'learning_rate': 2.1076923076923078e-05, 'epoch': 1.904, 'step': 2380}\n",
      "{'loss': 0.135382080078125, 'learning_rate': 2.0923076923076923e-05, 'epoch': 1.912, 'step': 2390}\n",
      "{'loss': 0.07723388671875, 'learning_rate': 2.0769230769230772e-05, 'epoch': 1.92, 'step': 2400}\n",
      "{'loss': 0.244775390625, 'learning_rate': 2.0615384615384617e-05, 'epoch': 1.928, 'step': 2410}\n",
      "{'loss': 0.1469482421875, 'learning_rate': 2.0461538461538462e-05, 'epoch': 1.936, 'step': 2420}\n",
      "{'loss': 0.17042236328125, 'learning_rate': 2.0307692307692308e-05, 'epoch': 1.944, 'step': 2430}\n",
      "{'loss': 0.09532470703125, 'learning_rate': 2.0153846153846153e-05, 'epoch': 1.952, 'step': 2440}\n",
      "{'loss': 0.180108642578125, 'learning_rate': 2e-05, 'epoch': 1.96, 'step': 2450}\n",
      "{'loss': 0.140313720703125, 'learning_rate': 1.9846153846153847e-05, 'epoch': 1.968, 'step': 2460}\n",
      "{'loss': 0.1453369140625, 'learning_rate': 1.9692307692307692e-05, 'epoch': 1.976, 'step': 2470}\n",
      "{'loss': 0.143768310546875, 'learning_rate': 1.9538461538461537e-05, 'epoch': 1.984, 'step': 2480}\n",
      "{'loss': 0.1611572265625, 'learning_rate': 1.9384615384615383e-05, 'epoch': 1.992, 'step': 2490}\n",
      "{'loss': 0.168548583984375, 'learning_rate': 1.923076923076923e-05, 'epoch': 2.0, 'step': 2500}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b525a4f985c347b1827b3eec279d4527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1250.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.02349853515625, 'learning_rate': 1.9076923076923077e-05, 'epoch': 2.008, 'step': 2510}\n",
      "{'loss': 0.05341796875, 'learning_rate': 1.8923076923076925e-05, 'epoch': 2.016, 'step': 2520}\n",
      "{'loss': 0.01732177734375, 'learning_rate': 1.876923076923077e-05, 'epoch': 2.024, 'step': 2530}\n",
      "{'loss': 0.050555419921875, 'learning_rate': 1.8615384615384616e-05, 'epoch': 2.032, 'step': 2540}\n",
      "{'loss': 0.10009765625, 'learning_rate': 1.8461538461538465e-05, 'epoch': 2.04, 'step': 2550}\n",
      "{'loss': 0.0193603515625, 'learning_rate': 1.830769230769231e-05, 'epoch': 2.048, 'step': 2560}\n",
      "{'loss': 0.153326416015625, 'learning_rate': 1.8153846153846155e-05, 'epoch': 2.056, 'step': 2570}\n",
      "{'loss': 0.0282470703125, 'learning_rate': 1.8e-05, 'epoch': 2.064, 'step': 2580}\n",
      "{'loss': 0.084930419921875, 'learning_rate': 1.7846153846153846e-05, 'epoch': 2.072, 'step': 2590}\n",
      "{'loss': 0.074578857421875, 'learning_rate': 1.7692307692307694e-05, 'epoch': 2.08, 'step': 2600}\n",
      "{'loss': 0.068365478515625, 'learning_rate': 1.753846153846154e-05, 'epoch': 2.088, 'step': 2610}\n",
      "{'loss': 0.05732421875, 'learning_rate': 1.7384615384615385e-05, 'epoch': 2.096, 'step': 2620}\n",
      "{'loss': 0.038543701171875, 'learning_rate': 1.723076923076923e-05, 'epoch': 2.104, 'step': 2630}\n",
      "{'loss': 0.005572509765625, 'learning_rate': 1.7076923076923076e-05, 'epoch': 2.112, 'step': 2640}\n",
      "{'loss': 0.075885009765625, 'learning_rate': 1.6923076923076924e-05, 'epoch': 2.12, 'step': 2650}\n",
      "{'loss': 0.08642578125, 'learning_rate': 1.676923076923077e-05, 'epoch': 2.128, 'step': 2660}\n",
      "{'loss': 0.040240478515625, 'learning_rate': 1.6615384615384615e-05, 'epoch': 2.136, 'step': 2670}\n",
      "{'loss': 0.03115234375, 'learning_rate': 1.646153846153846e-05, 'epoch': 2.144, 'step': 2680}\n",
      "{'loss': 0.08721923828125, 'learning_rate': 1.630769230769231e-05, 'epoch': 2.152, 'step': 2690}\n",
      "{'loss': 0.070867919921875, 'learning_rate': 1.6153846153846154e-05, 'epoch': 2.16, 'step': 2700}\n",
      "{'loss': 0.04532470703125, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.168, 'step': 2710}\n",
      "{'loss': 0.029302978515625, 'learning_rate': 1.5846153846153848e-05, 'epoch': 2.176, 'step': 2720}\n",
      "{'loss': 0.0650146484375, 'learning_rate': 1.5692307692307693e-05, 'epoch': 2.184, 'step': 2730}\n",
      "{'loss': 0.05201416015625, 'learning_rate': 1.553846153846154e-05, 'epoch': 2.192, 'step': 2740}\n",
      "{'loss': 0.0274658203125, 'learning_rate': 1.5384615384615387e-05, 'epoch': 2.2, 'step': 2750}\n",
      "{'loss': 0.0964111328125, 'learning_rate': 1.5230769230769232e-05, 'epoch': 2.208, 'step': 2760}\n",
      "{'loss': 0.04730224609375, 'learning_rate': 1.5076923076923078e-05, 'epoch': 2.216, 'step': 2770}\n",
      "{'loss': 0.130218505859375, 'learning_rate': 1.4923076923076923e-05, 'epoch': 2.224, 'step': 2780}\n",
      "{'loss': 0.078680419921875, 'learning_rate': 1.4769230769230772e-05, 'epoch': 2.232, 'step': 2790}\n",
      "{'loss': 0.08497314453125, 'learning_rate': 1.4615384615384617e-05, 'epoch': 2.24, 'step': 2800}\n",
      "{'loss': 0.033538818359375, 'learning_rate': 1.4461538461538462e-05, 'epoch': 2.248, 'step': 2810}\n",
      "{'loss': 0.067437744140625, 'learning_rate': 1.4307692307692308e-05, 'epoch': 2.2560000000000002, 'step': 2820}\n",
      "{'loss': 0.080718994140625, 'learning_rate': 1.4153846153846153e-05, 'epoch': 2.2640000000000002, 'step': 2830}\n",
      "{'loss': 0.06171875, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.2720000000000002, 'step': 2840}\n",
      "{'loss': 0.0417724609375, 'learning_rate': 1.3846153846153847e-05, 'epoch': 2.2800000000000002, 'step': 2850}\n",
      "{'loss': 0.0580322265625, 'learning_rate': 1.3692307692307694e-05, 'epoch': 2.288, 'step': 2860}\n",
      "{'loss': 0.036431884765625, 'learning_rate': 1.3538461538461539e-05, 'epoch': 2.296, 'step': 2870}\n",
      "{'loss': 0.148529052734375, 'learning_rate': 1.3384615384615384e-05, 'epoch': 2.304, 'step': 2880}\n",
      "{'loss': 0.05357666015625, 'learning_rate': 1.3230769230769233e-05, 'epoch': 2.312, 'step': 2890}\n",
      "{'loss': 0.056890869140625, 'learning_rate': 1.3076923076923078e-05, 'epoch': 2.32, 'step': 2900}\n",
      "{'loss': 0.031982421875, 'learning_rate': 1.2923076923076924e-05, 'epoch': 2.328, 'step': 2910}\n",
      "{'loss': 0.060748291015625, 'learning_rate': 1.2769230769230769e-05, 'epoch': 2.336, 'step': 2920}\n",
      "{'loss': 0.0051513671875, 'learning_rate': 1.2615384615384616e-05, 'epoch': 2.344, 'step': 2930}\n",
      "{'loss': 0.089892578125, 'learning_rate': 1.2461538461538463e-05, 'epoch': 2.352, 'step': 2940}\n",
      "{'loss': 0.0547607421875, 'learning_rate': 1.230769230769231e-05, 'epoch': 2.36, 'step': 2950}\n",
      "{'loss': 0.119097900390625, 'learning_rate': 1.2153846153846155e-05, 'epoch': 2.368, 'step': 2960}\n",
      "{'loss': 0.060577392578125, 'learning_rate': 1.2e-05, 'epoch': 2.376, 'step': 2970}\n",
      "{'loss': 0.0747802734375, 'learning_rate': 1.1846153846153847e-05, 'epoch': 2.384, 'step': 2980}\n",
      "{'loss': 0.177520751953125, 'learning_rate': 1.1692307692307693e-05, 'epoch': 2.392, 'step': 2990}\n",
      "{'loss': 0.048895263671875, 'learning_rate': 1.153846153846154e-05, 'epoch': 2.4, 'step': 3000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27392280da948499f6e3b9ff992f601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=79.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.2961650329589844, 'epoch': 2.4, 'step': 3000}\n",
      "{'loss': 0.006439208984375, 'learning_rate': 1.1384615384615385e-05, 'epoch': 2.408, 'step': 3010}\n",
      "{'loss': 0.06851806640625, 'learning_rate': 1.123076923076923e-05, 'epoch': 2.416, 'step': 3020}\n",
      "{'loss': 0.110247802734375, 'learning_rate': 1.1076923076923077e-05, 'epoch': 2.424, 'step': 3030}\n",
      "{'loss': 0.1262451171875, 'learning_rate': 1.0923076923076924e-05, 'epoch': 2.432, 'step': 3040}\n",
      "{'loss': 0.041033935546875, 'learning_rate': 1.0769230769230771e-05, 'epoch': 2.44, 'step': 3050}\n",
      "{'loss': 0.06932373046875, 'learning_rate': 1.0615384615384616e-05, 'epoch': 2.448, 'step': 3060}\n",
      "{'loss': 0.0596923828125, 'learning_rate': 1.0461538461538462e-05, 'epoch': 2.456, 'step': 3070}\n",
      "{'loss': 0.158453369140625, 'learning_rate': 1.0307692307692309e-05, 'epoch': 2.464, 'step': 3080}\n",
      "{'loss': 0.1104736328125, 'learning_rate': 1.0153846153846154e-05, 'epoch': 2.472, 'step': 3090}\n",
      "{'loss': 0.04942626953125, 'learning_rate': 1e-05, 'epoch': 2.48, 'step': 3100}\n",
      "{'loss': 0.01929931640625, 'learning_rate': 9.846153846153846e-06, 'epoch': 2.488, 'step': 3110}\n",
      "{'loss': 0.004931640625, 'learning_rate': 9.692307692307691e-06, 'epoch': 2.496, 'step': 3120}\n",
      "{'loss': 0.043023681640625, 'learning_rate': 9.538461538461538e-06, 'epoch': 2.504, 'step': 3130}\n",
      "{'loss': 0.080010986328125, 'learning_rate': 9.384615384615385e-06, 'epoch': 2.512, 'step': 3140}\n",
      "{'loss': 0.03382568359375, 'learning_rate': 9.230769230769232e-06, 'epoch': 2.52, 'step': 3150}\n",
      "{'loss': 0.04691162109375, 'learning_rate': 9.076923076923078e-06, 'epoch': 2.528, 'step': 3160}\n",
      "{'loss': 0.101544189453125, 'learning_rate': 8.923076923076923e-06, 'epoch': 2.536, 'step': 3170}\n",
      "{'loss': 0.104425048828125, 'learning_rate': 8.76923076923077e-06, 'epoch': 2.544, 'step': 3180}\n",
      "{'loss': 0.072857666015625, 'learning_rate': 8.615384615384615e-06, 'epoch': 2.552, 'step': 3190}\n",
      "{'loss': 0.10777587890625, 'learning_rate': 8.461538461538462e-06, 'epoch': 2.56, 'step': 3200}\n",
      "{'loss': 0.039007568359375, 'learning_rate': 8.307692307692307e-06, 'epoch': 2.568, 'step': 3210}\n",
      "{'loss': 0.081378173828125, 'learning_rate': 8.153846153846154e-06, 'epoch': 2.576, 'step': 3220}\n",
      "{'loss': 0.011517333984375, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.584, 'step': 3230}\n",
      "{'loss': 0.10721435546875, 'learning_rate': 7.846153846153847e-06, 'epoch': 2.592, 'step': 3240}\n",
      "{'loss': 0.050189208984375, 'learning_rate': 7.692307692307694e-06, 'epoch': 2.6, 'step': 3250}\n",
      "{'loss': 0.042974853515625, 'learning_rate': 7.538461538461539e-06, 'epoch': 2.608, 'step': 3260}\n",
      "{'loss': 0.0243896484375, 'learning_rate': 7.384615384615386e-06, 'epoch': 2.616, 'step': 3270}\n",
      "{'loss': 0.032037353515625, 'learning_rate': 7.230769230769231e-06, 'epoch': 2.624, 'step': 3280}\n",
      "{'loss': 0.002435302734375, 'learning_rate': 7.076923076923076e-06, 'epoch': 2.632, 'step': 3290}\n",
      "{'loss': 0.031939697265625, 'learning_rate': 6.923076923076923e-06, 'epoch': 2.64, 'step': 3300}\n",
      "{'loss': 0.126873779296875, 'learning_rate': 6.7692307692307695e-06, 'epoch': 2.648, 'step': 3310}\n",
      "{'loss': 0.043011474609375, 'learning_rate': 6.6153846153846165e-06, 'epoch': 2.656, 'step': 3320}\n",
      "{'loss': 0.121075439453125, 'learning_rate': 6.461538461538462e-06, 'epoch': 2.664, 'step': 3330}\n",
      "{'loss': 0.001904296875, 'learning_rate': 6.307692307692308e-06, 'epoch': 2.672, 'step': 3340}\n",
      "{'loss': 0.0843505859375, 'learning_rate': 6.153846153846155e-06, 'epoch': 2.68, 'step': 3350}\n",
      "{'loss': 0.0613525390625, 'learning_rate': 6e-06, 'epoch': 2.6879999999999997, 'step': 3360}\n",
      "{'loss': 0.134149169921875, 'learning_rate': 5.846153846153846e-06, 'epoch': 2.6959999999999997, 'step': 3370}\n",
      "{'loss': 0.088385009765625, 'learning_rate': 5.692307692307692e-06, 'epoch': 2.7039999999999997, 'step': 3380}\n",
      "{'loss': 0.081817626953125, 'learning_rate': 5.5384615384615385e-06, 'epoch': 2.7119999999999997, 'step': 3390}\n",
      "{'loss': 0.103680419921875, 'learning_rate': 5.3846153846153855e-06, 'epoch': 2.7199999999999998, 'step': 3400}\n",
      "{'loss': 0.013922119140625, 'learning_rate': 5.230769230769231e-06, 'epoch': 2.7279999999999998, 'step': 3410}\n",
      "{'loss': 0.059619140625, 'learning_rate': 5.076923076923077e-06, 'epoch': 2.7359999999999998, 'step': 3420}\n",
      "{'loss': 0.09356689453125, 'learning_rate': 4.923076923076923e-06, 'epoch': 2.7439999999999998, 'step': 3430}\n",
      "{'loss': 0.074383544921875, 'learning_rate': 4.769230769230769e-06, 'epoch': 2.752, 'step': 3440}\n",
      "{'loss': 0.133795166015625, 'learning_rate': 4.615384615384616e-06, 'epoch': 2.76, 'step': 3450}\n",
      "{'loss': 0.091644287109375, 'learning_rate': 4.4615384615384614e-06, 'epoch': 2.768, 'step': 3460}\n",
      "{'loss': 0.106689453125, 'learning_rate': 4.3076923076923076e-06, 'epoch': 2.776, 'step': 3470}\n",
      "{'loss': 0.030230712890625, 'learning_rate': 4.153846153846154e-06, 'epoch': 2.784, 'step': 3480}\n",
      "{'loss': 0.001885986328125, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.792, 'step': 3490}\n",
      "{'loss': 0.0563720703125, 'learning_rate': 3.846153846153847e-06, 'epoch': 2.8, 'step': 3500}\n",
      "{'loss': 0.06876220703125, 'learning_rate': 3.692307692307693e-06, 'epoch': 2.808, 'step': 3510}\n",
      "{'loss': 0.048626708984375, 'learning_rate': 3.538461538461538e-06, 'epoch': 2.816, 'step': 3520}\n",
      "{'loss': 0.087518310546875, 'learning_rate': 3.3846153846153848e-06, 'epoch': 2.824, 'step': 3530}\n",
      "{'loss': 0.00804443359375, 'learning_rate': 3.230769230769231e-06, 'epoch': 2.832, 'step': 3540}\n",
      "{'loss': 0.076165771484375, 'learning_rate': 3.0769230769230774e-06, 'epoch': 2.84, 'step': 3550}\n",
      "{'loss': 0.027899169921875, 'learning_rate': 2.923076923076923e-06, 'epoch': 2.848, 'step': 3560}\n",
      "{'loss': 0.062445068359375, 'learning_rate': 2.7692307692307693e-06, 'epoch': 2.856, 'step': 3570}\n",
      "{'loss': 0.069842529296875, 'learning_rate': 2.6153846153846154e-06, 'epoch': 2.864, 'step': 3580}\n",
      "{'loss': 0.108074951171875, 'learning_rate': 2.4615384615384615e-06, 'epoch': 2.872, 'step': 3590}\n",
      "{'loss': 0.129083251953125, 'learning_rate': 2.307692307692308e-06, 'epoch': 2.88, 'step': 3600}\n",
      "{'loss': 0.007867431640625, 'learning_rate': 2.1538461538461538e-06, 'epoch': 2.888, 'step': 3610}\n",
      "{'loss': 0.03380126953125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.896, 'step': 3620}\n",
      "{'loss': 0.002923583984375, 'learning_rate': 1.8461538461538465e-06, 'epoch': 2.904, 'step': 3630}\n",
      "{'loss': 0.039056396484375, 'learning_rate': 1.6923076923076924e-06, 'epoch': 2.912, 'step': 3640}\n",
      "{'loss': 0.024359130859375, 'learning_rate': 1.5384615384615387e-06, 'epoch': 2.92, 'step': 3650}\n",
      "{'loss': 0.002825927734375, 'learning_rate': 1.3846153846153846e-06, 'epoch': 2.928, 'step': 3660}\n",
      "{'loss': 0.0612548828125, 'learning_rate': 1.2307692307692308e-06, 'epoch': 2.936, 'step': 3670}\n",
      "{'loss': 0.095050048828125, 'learning_rate': 1.0769230769230769e-06, 'epoch': 2.944, 'step': 3680}\n",
      "{'loss': 0.021600341796875, 'learning_rate': 9.230769230769232e-07, 'epoch': 2.952, 'step': 3690}\n",
      "{'loss': 0.035504150390625, 'learning_rate': 7.692307692307694e-07, 'epoch': 2.96, 'step': 3700}\n",
      "{'loss': 0.026885986328125, 'learning_rate': 6.153846153846154e-07, 'epoch': 2.968, 'step': 3710}\n",
      "{'loss': 0.0342041015625, 'learning_rate': 4.615384615384616e-07, 'epoch': 2.976, 'step': 3720}\n",
      "{'loss': 0.0604736328125, 'learning_rate': 3.076923076923077e-07, 'epoch': 2.984, 'step': 3730}\n",
      "{'loss': 0.06240234375, 'learning_rate': 1.5384615384615385e-07, 'epoch': 2.992, 'step': 3740}\n",
      "{'loss': 0.077252197265625, 'learning_rate': 0.0, 'epoch': 3.0, 'step': 3750}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.1823802734375)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    overwrite_output_dir=True,\n",
    "    do_eval = True,\n",
    "    evaluate_during_training =True,\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eb45e4ec474f25889817b9a2ac5b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=391.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check=trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9308"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels,np.argmax(check.predictions,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBert scores 93% accuracy on the test set while the LSTM scored 84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
